### Assignment : Part 2 model improvement

#### Missing values

If we have a look to the Name variable for people whose age is missing we observe that there are 6 different status/particle in their names :

+ Jr
+ Mr
+ Mrs
+ Miss
+ Master
+ Sir

```{r tidy=FALSE}
train <- read.csv("train.csv")
head(train$Name[complete.cases(train)==FALSE])
```

If calculate the median age for complete cases for people with the same status/particle, we may infer the age for uncompleted cases. This method should be more precise than a simple raw median imputation.

```{r tidy=FALSE}
(jr <- median(train$Age[complete.cases(train)][grep("Jr",train$Name[complete.cases(train)])]))
(mr <- median(train$Age[complete.cases(train)][grep("Mr",train$Name[complete.cases(train)])]))
(mrs <- median(train$Age[complete.cases(train)][grep("Mrs",train$Name[complete.cases(train)])]))
(miss <- median(train$Age[complete.cases(train)][grep("Miss",train$Name[complete.cases(train)])]))
(master <- median(train$Age[complete.cases(train)][grep("Master",train$Name[complete.cases(train)])]))
(sir <- median(train$Age[complete.cases(train)][grep("Sir",train$Name[complete.cases(train)])]))
train_ <- subset(train, select=-c(PassengerId, Name, Ticket, Cabin))
uncomplete <- complete.cases(train)==FALSE
train_$Age[uncomplete][grep("Jr",train$Name[uncomplete])] <- jr
train_$Age[uncomplete][grep("Mr",train$Name[uncomplete])] <- mr 
train_$Age[uncomplete][grep("Mrs",train$Name[uncomplete])] <- mrs 
train_$Age[uncomplete][grep("Miss",train$Name[uncomplete])] <- miss 
train_$Age[uncomplete][grep("Master",train$Name[uncomplete])] <- master 
train_$Age[uncomplete][grep("Sir",train$Name[uncomplete])] <- sir
train_$Age[is.na(train_$Age)] <- median(train_$Age, na.rm=TRUE)
```

#### Binning continuous variables

In order to bin continuous variable in a relevant way I chose to plot the survival cumulative probability as a function of the age and fare.

For the plot related to the age we note that there are some stable bins (that is to say ranges where the curve increases steadily or stay flat) :

+ <= 1
+ 1 - 6
+ 6 - 15
+ 15 - 37
+ 37 - 49
+ 49 - 60
+ >= 60

```{r tidy=FALSE}
cumprob <- cumsum(train_$Survived[order(train_$Age)])/nrow(train)
plot(x=train_$Age[order(train_$Age)], y=cumprob, type='l', xlab="age", main='survival cumulative probability', xaxt='n')
axis(1,at=0:80,labels=0:80) 
```

Hence I decided to bin this variable accordingly.

```{r tidy=FALSE}
brk <- c(0,1,6,15,37,49,60,max(train_$Age))
train_$Age <- cut(train_$Age, breaks=brk, include.lowest=FALSE)
```

On the contrary there is no such pattern for the variable fare.

```{r tidy=FALSE}
cumprob <- cumsum(train_$Survived[order(train_$Fare)])/nrow(train)
plot(x=train_$Fare[order(train_$Fare)], y=cumprob, type='l', xlab="age", main='survival cumulative probability')
```


#### New variable

A variable that might be interesting is the fact that a passenger was alone aboard or not. Formaly a passenger can be considered alone if the sum of the variables SibSp and Parch equals 0.

```{r tidy=FALSE}
train_$Alone <- (train_$SibSp + train_$Parch)==0
```

#### Model improvement

Now we are going to compare the effect of the transformations explained above on the model.

If we have a look to the model performance due to the transformations performed on the age (imputation and binning) we note that the well classified ratio increases slightly ($81.6$% instead of the $80$% we got in the assignment part 1).

```{r tidy=FALSE}
set.seed(12345)
indices <- sample.int(round(0.7*nrow(train)))
logistic <- glm(Survived ~ . -Alone, data=train_[indices, ], family="binomial")
pred <- predict(logistic, newdata=train_[-indices, ])
check <- (pred>=0.5)==train[-indices, "Survived"]
sum(check)/length(pred)
```

Now if we have a look to the model performance due to the additional variable we added we can see that the ratio keep on increasing since we get a ratio equal to $82.7$%.

```{r tidy=FALSE}
logistic <- glm(Survived ~ . , data=train_[indices, ], family="binomial")
pred <- predict(logistic, newdata=train_[-indices, ])
check <- (pred>=0.5)==train[-indices, "Survived"]
sum(check)/length(pred)
```

Unfortunately those two models only reach a ratio of $76$% on the kaggle board (see screenshots logistic_model_2.png / logistic_model_3.png)